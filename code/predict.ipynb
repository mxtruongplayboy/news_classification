{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e716bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from text_cleaner import TextCleaner # Đảm bảo file text_cleaner.py ở cùng thư mục hoặc trong PYTHONPATH\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a12d0e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting py_vncorenlpNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached py_vncorenlp-0.1.4.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pyjnius (from py_vncorenlp)\n",
      "  Downloading pyjnius-1.6.1-cp310-cp310-win_amd64.whl.metadata (10 kB)\n",
      "Downloading pyjnius-1.6.1-cp310-cp310-win_amd64.whl (222 kB)\n",
      "Building wheels for collected packages: py_vncorenlp\n",
      "  Building wheel for py_vncorenlp (setup.py): started\n",
      "  Building wheel for py_vncorenlp (setup.py): finished with status 'done'\n",
      "  Created wheel for py_vncorenlp: filename=py_vncorenlp-0.1.4-py3-none-any.whl size=4392 sha256=70b02fb984584ad296f560afe4cb4bdecf3530d8c5f1d76f70868218c8e41ba4\n",
      "  Stored in directory: c:\\users\\mai xuan truong\\appdata\\local\\pip\\cache\\wheels\\d5\\d9\\bf\\62632cdb007c702a0664091e92a0bb1f18a2fcecbe962d9827\n",
      "Successfully built py_vncorenlp\n",
      "Installing collected packages: pyjnius, py_vncorenlp\n",
      "Successfully installed py_vncorenlp-0.1.4 pyjnius-1.6.1\n"
     ]
    }
   ],
   "source": [
    "%pip install py_vncorenlp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d18b7e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from text_cleaner import TextCleaner # Đảm bảo file text_cleaner.py ở cùng thư mục hoặc trong PYTHONPATH\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d5b23a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sử dụng MODEL_SAVE_DIR: E:\\LEARN_5\\XuLyNgonNguTuNhien\\project\\models\n"
     ]
    }
   ],
   "source": [
    "# --- 0. Configuration ---\n",
    "# THAY ĐỔI ĐƯỜNG DẪN NÀY CHO PHÙ HỢP VỚI THƯ MỤC BẠN ĐÃ LƯU MÔ HÌNH\n",
    "# Ví dụ:\n",
    "# MODEL_SAVE_DIR = r'E:\\LEARN_5\\XuLyNgonNguTuNhien\\project\\models_spacy'\n",
    "# HOẶC\n",
    "MODEL_SAVE_DIR = r'E:\\LEARN_5\\XuLyNgonNguTuNhien\\project\\models' # Ví dụ nếu bạn dùng model với Word2Vec\n",
    "# HOẶC\n",
    "# MODEL_SAVE_DIR = r'E:\\LEARN_5\\XuLyNgonNguTuNhien\\project\\models' # Thư mục gốc ban đầu\n",
    "\n",
    "print(f\"Sử dụng MODEL_SAVE_DIR: {MODEL_SAVE_DIR}\")\n",
    "if not os.path.exists(MODEL_SAVE_DIR):\n",
    "    print(f\"LỖI: Thư mục MODEL_SAVE_DIR '{MODEL_SAVE_DIR}' không tồn tại. Vui lòng kiểm tra lại đường dẫn.\")\n",
    "    exit()\n",
    "\n",
    "TOKENIZER_PATH = os.path.join(MODEL_SAVE_DIR, 'tokenizer.pkl')\n",
    "LABEL_ENCODER_PATH = os.path.join(MODEL_SAVE_DIR, 'label_encoder.pkl')\n",
    "MAX_LEN_PATH = os.path.join(MODEL_SAVE_DIR, 'max_len.pkl')\n",
    "BIGRU_MODEL_PATH = os.path.join(MODEL_SAVE_DIR, 'bigru_model.keras')\n",
    "BILSTM_MODEL_PATH = os.path.join(MODEL_SAVE_DIR, 'bilstm_model.keras')\n",
    "\n",
    "# Paths for TextCleaner\n",
    "STOPWORDS_FILE = 'E:\\\\LEARN_5\\\\XuLyNgonNguTuNhien\\\\project\\\\crawl\\\\stopwords.txt'\n",
    "ABBREVIATIONS_FILE = 'E:\\\\LEARN_5\\\\XuLyNgonNguTuNhien\\\\project\\\\crawl\\\\acronym.txt'\n",
    "VNCORENLP_MODEL_DIR = 'E:/LEARN_5/XuLyNgonNguTuNhien/vncorenlp'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cbaee93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Khởi tạo TextCleaner ---\n",
      "Đã tạo instance mới của TextCleaner.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Khởi tạo TextCleaner (Tương tự ví dụ của bạn) ---\n",
    "print(\"--- Khởi tạo TextCleaner ---\")\n",
    "cleaner_instance = None\n",
    "try:\n",
    "    if not os.path.exists(STOPWORDS_FILE): print(f\"CẢNH BÁO: File stopwords '{STOPWORDS_FILE}' không tồn tại.\")\n",
    "    if not os.path.exists(ABBREVIATIONS_FILE): print(f\"CẢNH BÁO: File viết tắt '{ABBREVIATIONS_FILE}' không tồn tại.\")\n",
    "    if not os.path.exists(VNCORENLP_MODEL_DIR): print(f\"CẢNH BÁO: Thư mục VnCoreNLP '{VNCORENLP_MODEL_DIR}' không tồn tại.\")\n",
    "\n",
    "    # Kiểm tra xem instance đã tồn tại chưa (mặc dù trong script độc lập này thì không cần thiết lắm)\n",
    "    if 'cleaner_instance' not in globals() or cleaner_instance is None:\n",
    "        cleaner_instance = TextCleaner(STOPWORDS_FILE, ABBREVIATIONS_FILE, VNCORENLP_MODEL_DIR)\n",
    "        print(\"Đã tạo instance mới của TextCleaner.\")\n",
    "    else:\n",
    "        print(\"Instance của TextCleaner đã tồn tại. Bỏ qua khởi tạo.\")\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi khi khởi tạo TextCleaner: {e}. Không thể làm sạch văn bản.\")\n",
    "    # Để script có thể tiếp tục (nếu muốn test phần tải model), không exit() ở đây\n",
    "    # nhưng hàm dự đoán sẽ không hoạt động nếu cleaner_instance là None.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "155bdb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tải các thành phần đã lưu ---\n",
      "Đã tải tokenizer từ E:\\LEARN_5\\XuLyNgonNguTuNhien\\project\\models\\tokenizer.pkl.\n",
      "Đã tải label encoder từ E:\\LEARN_5\\XuLyNgonNguTuNhien\\project\\models\\label_encoder.pkl.\n",
      "Đã tải max_len: 200 từ E:\\LEARN_5\\XuLyNgonNguTuNhien\\project\\models\\max_len.pkl\n",
      "Đã tải mô hình BiGRU từ E:\\LEARN_5\\XuLyNgonNguTuNhien\\project\\models\\bigru_model.keras.\n",
      "Đã tải mô hình BiLSTM từ E:\\LEARN_5\\XuLyNgonNguTuNhien\\project\\models\\bilstm_model.keras.\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Tải các thành phần đã lưu ---\n",
    "print(\"\\n--- Tải các thành phần đã lưu ---\")\n",
    "tokenizer = None\n",
    "label_encoder = None\n",
    "max_len = None\n",
    "bigru_model = None\n",
    "bilstm_model = None\n",
    "\n",
    "try:\n",
    "    with open(TOKENIZER_PATH, 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "    print(f\"Đã tải tokenizer từ {TOKENIZER_PATH}.\")\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi khi tải tokenizer: {e}.\")\n",
    "\n",
    "try:\n",
    "    with open(LABEL_ENCODER_PATH, 'rb') as handle:\n",
    "        label_encoder = pickle.load(handle)\n",
    "    print(f\"Đã tải label encoder từ {LABEL_ENCODER_PATH}.\")\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi khi tải label encoder: {e}.\")\n",
    "\n",
    "try:\n",
    "    with open(MAX_LEN_PATH, 'rb') as handle:\n",
    "        max_len = pickle.load(handle)\n",
    "    print(f\"Đã tải max_len: {max_len} từ {MAX_LEN_PATH}\")\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi khi tải max_len: {e}.\")\n",
    "\n",
    "try:\n",
    "    bigru_model = load_model(BIGRU_MODEL_PATH)\n",
    "    print(f\"Đã tải mô hình BiGRU từ {BIGRU_MODEL_PATH}.\")\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi khi tải mô hình BiGRU: {e}.\")\n",
    "\n",
    "try:\n",
    "    bilstm_model = load_model(BILSTM_MODEL_PATH)\n",
    "    print(f\"Đã tải mô hình BiLSTM từ {BILSTM_MODEL_PATH}.\")\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi khi tải mô hình BiLSTM: {e}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62e7c201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Chuẩn bị dữ liệu mẫu ---\n",
      "Dữ liệu mẫu đã được làm sạch.\n",
      "Văn bản đã làm sạch (200 ký tự đầu): \"công_nghệ ngã đường trí_tuệ_nhân_tạo hãng công_nghệ hàng_đầu apple facebook google loay_hoay bối_cảnh trí_tuệ_nhân_tạo phát_triển thần_tốc trí_tuệ_nhân_tạo coi kẻ quấy_phá thung_lũng silicon tập_đoàn ...\"\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Dữ liệu mẫu và làm sạch (Tương tự ví dụ của bạn) ---\n",
    "print(\"\\n--- Chuẩn bị dữ liệu mẫu ---\")\n",
    "sample_title = \"Các ông lớn công nghệ giữa ngã ba đường vì AI\"\n",
    "sample_description = \"Các hãng công nghệ hàng đầu như Apple, Facebook, Google được đánh giá bắt đầu loay hoay tìm cách thay đổi trong bối cảnh AI phát triển thần tốc.\"\n",
    "sample_content = \"AI đang được coi là \\\"kẻ quấy phá\\\" ở Thung lũng Silicon, đặc biệt với các tập đoàn lâu đời như Apple (49 năm), Google (26 năm), Meta (21 năm) hay Amazon (31 năm) \\\"Công bằng mà nói, chưa Big Tech nào gặp khó khăn. Họ vẫn là trụ cột của nước Mỹ với tổng vốn hóa thị trường trên 7.000 tỷ USD\\\", WSJ bình luận. \\\"Tuy nhiên, họ đều đang cùng nhau đứng ở ngã ba đường và tiến thoái lưỡng nan, điều cuốn sách kinh doanh kinh điển The Innovator's Dilemma từng đề cập\\\" \\\"The Innovator's Dilemma (Thách thức sáng tạo) của tác giả Clayton Christensen giải thích cách các sản phẩm, dịch vụ mới \\\"lật đổ\\\" cái cũ. Cuốn sách nhắc đến thuật ngữ disruption, ý nói các công ty lớn và thành công có thể thất bại trước sự xuất hiện công ty nhỏ sở hữu công nghệ, quy trình đột phá. Giống như Internet từng \\\"thanh lọc\\\" nhiều doanh nghiệp truyền thống, AI cũng có thể khiến các ông lớn công nghệ hiện nay phải thay đổi hoặc chung số phận\\\" \\\"Theo Bloomberg, tại phiên tòa chống độc quyền của Bộ Tư pháp đối với Google tuần trước, Eddy Cue, Phó chủ tịch mảng dịch vụ của Apple, cho biết lượng truy vấn tìm kiếm của Google trên thiết bị công ty lần đầu tiên giảm sau 20 năm vào tháng trước. Dù Google phủ nhận, CNN nhận định tiết lộ của Eddy Cue cho thấy người dùng đang dần chuyển sang hỏi đáp thông tin bằng chatbot AI. Năm ngoái, công ty nghiên cứu thị trường Gartner ước tính tìm kiếm trực tuyến kiểu truyền thông sẽ giảm 25% vào năm 2026 do AI trở nên thịnh hành\\\" \\\"CEO Apple Tim Cook cũng đang phải trấn an nhà đầu tư trước sự chậm trễ triển khai AI trên iPhone. \\\"Chúng tôi cần thêm thời gian để hoàn thành đúng theo tiêu chuẩn chất lượng cao nhất\\\", ông nói trong cuộc họp trước giới đầu tư tuần trước về Apple Intelligence\\\" \\\"Trong khi đó, Mark Zuckerberg, CEO Meta, cho biết người dùng đang giảm việc chia sẻ với bạn bè trên Facebook. Theo giới chuyên gia, điều này một phần do mạng xã hội hơn 20 năm tuổi trở nên \\\"già cỗi\\\" trước sự mới mẻ của TikTok với thuật toán AI đề xuất nội dung\\\" \\\"Một số đã triển khai giải pháp riêng, như Meta tung ra chatbot Meta AI, Google có mô hình Gemini còn Microsoft phát triển Copilot. Tuy nhiên, chưa ai tìm ra \\\"công thức chiến thắng\\\". Họ đang ở ngã ba đường: có quy mô quá lớn, không thể xóa bỏ hoàn toàn mô hình cũ để mạnh dạn thử nghiệm những thứ mới mẻ như các startup nhỏ\\\" \\\"Bạn không thể gắn bó với một khuôn khổ hoạt động hoặc một cách làm cụ thể nào đó trong thời AI\\\", Karl Mozurkewich, kiến trúc sư trưởng tại công ty điện toán đám mây Valdi, viết trên blog\\\" \\\"Điều này mang lại hy vọng cho những người như Sarah Guo, nhà đầu tư mạo hiểm trẻ ở Thung lũng Silicon. Cô đang tìm kiếm startup AI hấp dẫn tiếp theo - những công ty có thể hạ bệ ông lớn. \\\"Với công ty đã thành danh, việc sáng tạo sản phẩm mới sẽ đầy rủi ro\\\", Guo nói trong podcast Bold Names phát sóng tuần trước\\\" \\\"Đây là điều tôi thích nhất về AI\\\", Theo Brown, nhà phát triển Ping, nói. \\\"Nó biến những thứ trước đây ngành công nghệ coi là siêu giá trị và thiêng liêng thành thứ cực kỳ rẻ và dễ vứt bỏ\\\" \\\"Không phải hãng công nghệ lớn nào cũng bị tác động theo hướng tiêu cực. Nvidia, ra đời cách đây 32 năm, phát triển bùng nổ nhờ cơn khát GPU dùng để huấn luyện AI. Tuy nhiên, sự xuất hiện của các mô hình giá rẻ như DeepSeek cũng đặt ra câu hỏi liệu có cần đầu tư quá nhiều tiền vào chip AI như hiện nay\\\" \\\"Tất cả đang trong tình huống tiến thoái lưỡng nan, dù chưa có ai thực sự gặp khủng hoảng\\\", WSJ bình luận.\"\n",
    "cleaned_sample_text = \"\"\n",
    "if cleaner_instance:\n",
    "    try:\n",
    "        title_c, desc_c, content_c = cleaner_instance.process_text(sample_title, sample_description, sample_content)\n",
    "        cleaned_sample_text = title_c + \" \" + desc_c + \" \" + content_c\n",
    "        print(\"Dữ liệu mẫu đã được làm sạch.\")\n",
    "        print(f\"Văn bản đã làm sạch (200 ký tự đầu): \\\"{cleaned_sample_text[:200]}...\\\"\")\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi làm sạch dữ liệu mẫu: {e}\")\n",
    "else:\n",
    "    print(\"TextCleaner không khả dụng, không thể làm sạch dữ liệu mẫu.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d45cd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Hàm dự đoán (Tương tự ví dụ của bạn, nhưng cho RNN) ---\n",
    "def predict_new_text_rnn(cleaned_text_input, model_to_use, model_name_str,\n",
    "                         tokenizer_loaded, label_encoder_loaded, max_len_loaded):\n",
    "    # Kiểm tra các thành phần cần thiết\n",
    "    if model_to_use is None:\n",
    "        print(f\"Mô hình {model_name_str} chưa được tải hoặc có lỗi. Bỏ qua dự đoán.\")\n",
    "        return\n",
    "    if tokenizer_loaded is None:\n",
    "        print(\"Tokenizer chưa được tải. Bỏ qua dự đoán.\")\n",
    "        return\n",
    "    if label_encoder_loaded is None:\n",
    "        print(\"Label encoder chưa được tải. Bỏ qua dự đoán.\")\n",
    "        return\n",
    "    if max_len_loaded is None:\n",
    "        print(\"Max_len chưa được tải. Bỏ qua dự đoán.\")\n",
    "        return\n",
    "    if not cleaned_text_input or not cleaned_text_input.strip():\n",
    "        print(\"Văn bản đầu vào (đã làm sạch) rỗng. Không thể dự đoán.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n--- Dự đoán với {model_name_str} cho văn bản mới ---\")\n",
    "    print(f\"Văn bản đầu vào (200 ký tự đầu): \\\"{cleaned_text_input[:200]}...\\\"\")\n",
    "\n",
    "    # Tokenize and Pad\n",
    "    try:\n",
    "        sequence = tokenizer_loaded.texts_to_sequences([cleaned_text_input])\n",
    "        padded_sequence = pad_sequences(sequence, maxlen=max_len_loaded, padding='post', truncating='post')\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi trong quá trình tokenize hoặc padding: {e}\")\n",
    "        return\n",
    "\n",
    "    # Predict\n",
    "    try:\n",
    "        prediction_proba = model_to_use.predict(padded_sequence)\n",
    "        predicted_class_index = np.argmax(prediction_proba, axis=1)[0]\n",
    "        predicted_class_label = label_encoder_loaded.inverse_transform([predicted_class_index])[0]\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi trong quá trình dự đoán của mô hình: {e}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Chủ đề dự đoán: {predicted_class_label}\")\n",
    "    print(\"Xác suất dự đoán cho từng chủ đề:\")\n",
    "    if hasattr(label_encoder_loaded, 'classes_'):\n",
    "        for i, topic_class_name in enumerate(label_encoder_loaded.classes_):\n",
    "            print(f\"  - {topic_class_name}: {prediction_proba[0][i]:.4f}\")\n",
    "    else:\n",
    "        print(\"Không thể lấy tên các lớp từ label_encoder.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f929eb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Thực hiện dự đoán cho dữ liệu mẫu ---\n",
      "\n",
      "--- Dự đoán với BiGRU cho văn bản mới ---\n",
      "Văn bản đầu vào (200 ký tự đầu): \"công_nghệ ngã đường trí_tuệ_nhân_tạo hãng công_nghệ hàng_đầu apple facebook google loay_hoay bối_cảnh trí_tuệ_nhân_tạo phát_triển thần_tốc trí_tuệ_nhân_tạo coi kẻ quấy_phá thung_lũng silicon tập_đoàn ...\"\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "Chủ đề dự đoán: Chuyển đổi số\n",
      "Xác suất dự đoán cho từng chủ đề:\n",
      "  - AI: 0.2140\n",
      "  - Bóng đá: 0.0000\n",
      "  - Chuyển đổi số: 0.6300\n",
      "  - Chân dung: 0.0000\n",
      "  - Chính trị: 0.0000\n",
      "  - Chứng khoán: 0.0003\n",
      "  - Các môn thể thao khác: 0.0001\n",
      "  - Du học: 0.0000\n",
      "  - Dân sinh: 0.0000\n",
      "  - Ebank: 0.0001\n",
      "  - Giao thông: 0.0000\n",
      "  - Giáo dục 4.0: 0.0002\n",
      "  - Giải trí giới sao: 0.0002\n",
      "  - Giải trí làm đẹp: 0.0000\n",
      "  - Giải trí nhạc: 0.0000\n",
      "  - Giải trí phim: 0.0091\n",
      "  - Giải trí thời trang: 0.0020\n",
      "  - Hàng hóa: 0.0002\n",
      "  - Hậu trường thể thao: 0.0001\n",
      "  - Học tiếng anh: 0.0000\n",
      "  - Hồ sơ phá án: 0.0048\n",
      "  - Kinh doanh doanh nghiệp: 0.0017\n",
      "  - Kinh doanh quốc tế: 0.0097\n",
      "  - Người Việt 5 châu: 0.0004\n",
      "  - Nhịp sống: 0.0008\n",
      "  - Quân sự: 0.0001\n",
      "  - Quỹ Hy vọng: 0.0000\n",
      "  - Sân khấu mỹ thuật: 0.0002\n",
      "  - Sống khoẻ: 0.0000\n",
      "  - Thiết bị: 0.0039\n",
      "  - Thế giới tự nhiên: 0.0000\n",
      "  - Thị trường xe: 0.0005\n",
      "  - Tin tức Giáo dục: 0.0000\n",
      "  - Tin tức sức khoẻ: 0.0002\n",
      "  - Tổ ấm: 0.0005\n",
      "  - Việc làm: 0.0020\n",
      "  - Vũ trụ: 0.1190\n",
      "  - Ẩm thực: 0.0000\n",
      "\n",
      "--- Dự đoán với BiLSTM cho văn bản mới ---\n",
      "Văn bản đầu vào (200 ký tự đầu): \"công_nghệ ngã đường trí_tuệ_nhân_tạo hãng công_nghệ hàng_đầu apple facebook google loay_hoay bối_cảnh trí_tuệ_nhân_tạo phát_triển thần_tốc trí_tuệ_nhân_tạo coi kẻ quấy_phá thung_lũng silicon tập_đoàn ...\"\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "Chủ đề dự đoán: AI\n",
      "Xác suất dự đoán cho từng chủ đề:\n",
      "  - AI: 0.9797\n",
      "  - Bóng đá: 0.0001\n",
      "  - Chuyển đổi số: 0.0148\n",
      "  - Chân dung: 0.0005\n",
      "  - Chính trị: 0.0001\n",
      "  - Chứng khoán: 0.0000\n",
      "  - Các môn thể thao khác: 0.0000\n",
      "  - Du học: 0.0000\n",
      "  - Dân sinh: 0.0000\n",
      "  - Ebank: 0.0000\n",
      "  - Giao thông: 0.0000\n",
      "  - Giáo dục 4.0: 0.0002\n",
      "  - Giải trí giới sao: 0.0000\n",
      "  - Giải trí làm đẹp: 0.0000\n",
      "  - Giải trí nhạc: 0.0000\n",
      "  - Giải trí phim: 0.0001\n",
      "  - Giải trí thời trang: 0.0000\n",
      "  - Hàng hóa: 0.0000\n",
      "  - Hậu trường thể thao: 0.0000\n",
      "  - Học tiếng anh: 0.0017\n",
      "  - Hồ sơ phá án: 0.0000\n",
      "  - Kinh doanh doanh nghiệp: 0.0001\n",
      "  - Kinh doanh quốc tế: 0.0000\n",
      "  - Người Việt 5 châu: 0.0000\n",
      "  - Nhịp sống: 0.0000\n",
      "  - Quân sự: 0.0000\n",
      "  - Quỹ Hy vọng: 0.0000\n",
      "  - Sân khấu mỹ thuật: 0.0000\n",
      "  - Sống khoẻ: 0.0000\n",
      "  - Thiết bị: 0.0011\n",
      "  - Thế giới tự nhiên: 0.0000\n",
      "  - Thị trường xe: 0.0000\n",
      "  - Tin tức Giáo dục: 0.0001\n",
      "  - Tin tức sức khoẻ: 0.0000\n",
      "  - Tổ ấm: 0.0000\n",
      "  - Việc làm: 0.0012\n",
      "  - Vũ trụ: 0.0001\n",
      "  - Ẩm thực: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Thực hiện dự đoán (Tương tự ví dụ của bạn) ---\n",
    "print(\"\\n--- Thực hiện dự đoán cho dữ liệu mẫu ---\")\n",
    "if cleaned_sample_text: # Chỉ dự đoán nếu văn bản đã được làm sạch\n",
    "    if bigru_model:\n",
    "        predict_new_text_rnn(cleaned_sample_text, bigru_model, \"BiGRU\",\n",
    "                             tokenizer, label_encoder, max_len)\n",
    "    else:\n",
    "        print(\"Mô hình BiGRU không khả dụng để dự đoán.\")\n",
    "\n",
    "    if bilstm_model:\n",
    "        predict_new_text_rnn(cleaned_sample_text, bilstm_model, \"BiLSTM\",\n",
    "                             tokenizer, label_encoder, max_len)\n",
    "    else:\n",
    "        print(\"Mô hình BiLSTM không khả dụng để dự đoán.\")\n",
    "\n",
    "    if not bigru_model and not bilstm_model:\n",
    "        print(\"Không có mô hình RNN nào được tải thành công để thực hiện dự đoán.\")\n",
    "elif cleaner_instance is None:\n",
    "    print(\"Không thể dự đoán vì TextCleaner không được khởi tạo.\")\n",
    "else:\n",
    "    print(\"Không thể dự đoán vì dữ liệu mẫu chưa được làm sạch (có thể do lỗi ở TextCleaner).\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4efc6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Dự đoán cho dữ liệu mẫu thứ hai (tùy chọn) ---\n",
      "Dữ liệu mẫu 2 đã được làm sạch.\n",
      "\n",
      "--- Dự đoán với BiGRU cho văn bản mới ---\n",
      "Văn bản đầu vào (200 ký tự đầu): \"giá vàng giá vàng sjc vàng điều_chỉnh phiên đi ngang công_ty kinh_doanh vàng_bạc đá_quý đồng_loạt niêm_yết giá vàng sjc đồng giá vàng nhẫn ghi_nhận tương_tự biến_động ảnh_hưởng thị_trường vàng thế_giớ...\"\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "Chủ đề dự đoán: Hàng hóa\n",
      "Xác suất dự đoán cho từng chủ đề:\n",
      "  - AI: 0.0000\n",
      "  - Bóng đá: 0.0000\n",
      "  - Chuyển đổi số: 0.0001\n",
      "  - Chân dung: 0.0000\n",
      "  - Chính trị: 0.0000\n",
      "  - Chứng khoán: 0.0000\n",
      "  - Các môn thể thao khác: 0.0000\n",
      "  - Du học: 0.0000\n",
      "  - Dân sinh: 0.0000\n",
      "  - Ebank: 0.0002\n",
      "  - Giao thông: 0.0001\n",
      "  - Giáo dục 4.0: 0.0000\n",
      "  - Giải trí giới sao: 0.0000\n",
      "  - Giải trí làm đẹp: 0.0000\n",
      "  - Giải trí nhạc: 0.0000\n",
      "  - Giải trí phim: 0.0000\n",
      "  - Giải trí thời trang: 0.0000\n",
      "  - Hàng hóa: 0.9973\n",
      "  - Hậu trường thể thao: 0.0000\n",
      "  - Học tiếng anh: 0.0000\n",
      "  - Hồ sơ phá án: 0.0000\n",
      "  - Kinh doanh doanh nghiệp: 0.0003\n",
      "  - Kinh doanh quốc tế: 0.0006\n",
      "  - Người Việt 5 châu: 0.0001\n",
      "  - Nhịp sống: 0.0001\n",
      "  - Quân sự: 0.0000\n",
      "  - Quỹ Hy vọng: 0.0001\n",
      "  - Sân khấu mỹ thuật: 0.0000\n",
      "  - Sống khoẻ: 0.0000\n",
      "  - Thiết bị: 0.0000\n",
      "  - Thế giới tự nhiên: 0.0000\n",
      "  - Thị trường xe: 0.0000\n",
      "  - Tin tức Giáo dục: 0.0000\n",
      "  - Tin tức sức khoẻ: 0.0009\n",
      "  - Tổ ấm: 0.0000\n",
      "  - Việc làm: 0.0000\n",
      "  - Vũ trụ: 0.0000\n",
      "  - Ẩm thực: 0.0000\n",
      "\n",
      "--- Dự đoán với BiLSTM cho văn bản mới ---\n",
      "Văn bản đầu vào (200 ký tự đầu): \"giá vàng giá vàng sjc vàng điều_chỉnh phiên đi ngang công_ty kinh_doanh vàng_bạc đá_quý đồng_loạt niêm_yết giá vàng sjc đồng giá vàng nhẫn ghi_nhận tương_tự biến_động ảnh_hưởng thị_trường vàng thế_giớ...\"\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "Chủ đề dự đoán: Hàng hóa\n",
      "Xác suất dự đoán cho từng chủ đề:\n",
      "  - AI: 0.0000\n",
      "  - Bóng đá: 0.0000\n",
      "  - Chuyển đổi số: 0.0000\n",
      "  - Chân dung: 0.0000\n",
      "  - Chính trị: 0.0000\n",
      "  - Chứng khoán: 0.0006\n",
      "  - Các môn thể thao khác: 0.0004\n",
      "  - Du học: 0.0001\n",
      "  - Dân sinh: 0.0003\n",
      "  - Ebank: 0.0005\n",
      "  - Giao thông: 0.0001\n",
      "  - Giáo dục 4.0: 0.0000\n",
      "  - Giải trí giới sao: 0.0000\n",
      "  - Giải trí làm đẹp: 0.0000\n",
      "  - Giải trí nhạc: 0.0000\n",
      "  - Giải trí phim: 0.0000\n",
      "  - Giải trí thời trang: 0.0000\n",
      "  - Hàng hóa: 0.9736\n",
      "  - Hậu trường thể thao: 0.0000\n",
      "  - Học tiếng anh: 0.0000\n",
      "  - Hồ sơ phá án: 0.0000\n",
      "  - Kinh doanh doanh nghiệp: 0.0008\n",
      "  - Kinh doanh quốc tế: 0.0221\n",
      "  - Người Việt 5 châu: 0.0001\n",
      "  - Nhịp sống: 0.0002\n",
      "  - Quân sự: 0.0000\n",
      "  - Quỹ Hy vọng: 0.0000\n",
      "  - Sân khấu mỹ thuật: 0.0000\n",
      "  - Sống khoẻ: 0.0001\n",
      "  - Thiết bị: 0.0000\n",
      "  - Thế giới tự nhiên: 0.0000\n",
      "  - Thị trường xe: 0.0003\n",
      "  - Tin tức Giáo dục: 0.0000\n",
      "  - Tin tức sức khoẻ: 0.0002\n",
      "  - Tổ ấm: 0.0000\n",
      "  - Việc làm: 0.0000\n",
      "  - Vũ trụ: 0.0000\n",
      "  - Ẩm thực: 0.0004\n",
      "\n",
      "--- Kết thúc chương trình dự đoán ---\n"
     ]
    }
   ],
   "source": [
    "# Ví dụ với dữ liệu thứ hai (bạn có thể thêm)\n",
    "print(\"\\n--- Dự đoán cho dữ liệu mẫu thứ hai (tùy chọn) ---\")\n",
    "sample_title_2 = \"Giá vàng trong nước bất ngờ tăng mạnh\"\n",
    "sample_description_2 = \"Giá vàng SJC và các loại vàng khác đều điều chỉnh tăng sau nhiều phiên đi ngang.\"\n",
    "sample_content_2 = \"Sáng nay, các công ty kinh doanh vàng bạc đá quý lớn đồng loạt niêm yết giá vàng SJC tăng từ 200.000 đến 300.000 đồng mỗi lượng. Giá vàng nhẫn cũng ghi nhận mức tăng tương tự. Sự biến động này được cho là do ảnh hưởng từ thị trường vàng thế giới và tỷ giá USD/VND. Nhiều nhà đầu tư tỏ ra quan tâm và tìm kiếm cơ hội giao dịch.\"\n",
    "\n",
    "cleaned_sample_text_2 = \"\"\n",
    "if cleaner_instance:\n",
    "    try:\n",
    "        title_c2, desc_c2, content_c2 = cleaner_instance.process_text(sample_title_2, sample_description_2, sample_content_2)\n",
    "        cleaned_sample_text_2 = title_c2 + \" \" + desc_c2 + \" \" + content_c2\n",
    "        print(\"Dữ liệu mẫu 2 đã được làm sạch.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi làm sạch dữ liệu mẫu 2: {e}\")\n",
    "\n",
    "if cleaned_sample_text_2:\n",
    "    if bigru_model:\n",
    "        predict_new_text_rnn(cleaned_sample_text_2, bigru_model, \"BiGRU\",\n",
    "                             tokenizer, label_encoder, max_len)\n",
    "    if bilstm_model:\n",
    "        predict_new_text_rnn(cleaned_sample_text_2, bilstm_model, \"BiLSTM\",\n",
    "                             tokenizer, label_encoder, max_len)\n",
    "\n",
    "print(\"\\n--- Kết thúc chương trình dự đoán ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
