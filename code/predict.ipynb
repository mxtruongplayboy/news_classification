{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e716bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from text_cleaner import TextCleaner # Đảm bảo file text_cleaner.py ở cùng thư mục hoặc trong PYTHONPATH\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a12d0e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting py_vncorenlpNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached py_vncorenlp-0.1.4.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pyjnius (from py_vncorenlp)\n",
      "  Downloading pyjnius-1.6.1-cp310-cp310-win_amd64.whl.metadata (10 kB)\n",
      "Downloading pyjnius-1.6.1-cp310-cp310-win_amd64.whl (222 kB)\n",
      "Building wheels for collected packages: py_vncorenlp\n",
      "  Building wheel for py_vncorenlp (setup.py): started\n",
      "  Building wheel for py_vncorenlp (setup.py): finished with status 'done'\n",
      "  Created wheel for py_vncorenlp: filename=py_vncorenlp-0.1.4-py3-none-any.whl size=4392 sha256=70b02fb984584ad296f560afe4cb4bdecf3530d8c5f1d76f70868218c8e41ba4\n",
      "  Stored in directory: c:\\users\\mai xuan truong\\appdata\\local\\pip\\cache\\wheels\\d5\\d9\\bf\\62632cdb007c702a0664091e92a0bb1f18a2fcecbe962d9827\n",
      "Successfully built py_vncorenlp\n",
      "Installing collected packages: pyjnius, py_vncorenlp\n",
      "Successfully installed py_vncorenlp-0.1.4 pyjnius-1.6.1\n"
     ]
    }
   ],
   "source": [
    "%pip install py_vncorenlp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d18b7e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from text_cleaner import TextCleaner # Đảm bảo file text_cleaner.py ở cùng thư mục hoặc trong PYTHONPATH\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d5b23a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sử dụng MODEL_SAVE_DIR: E:\\LEARN_5\\XuLyNgonNguTuNhien\\project\\models\n"
     ]
    }
   ],
   "source": [
    "# --- 0. Configuration ---\n",
    "# THAY ĐỔI ĐƯỜNG DẪN NÀY CHO PHÙ HỢP VỚI THƯ MỤC BẠN ĐÃ LƯU MÔ HÌNH\n",
    "# Ví dụ:\n",
    "# MODEL_SAVE_DIR = r'E:\\LEARN_5\\XuLyNgonNguTuNhien\\project\\models_spacy'\n",
    "# HOẶC\n",
    "MODEL_SAVE_DIR = r'E:\\LEARN_5\\XuLyNgonNguTuNhien\\project\\models' # Ví dụ nếu bạn dùng model với Word2Vec\n",
    "# HOẶC\n",
    "# MODEL_SAVE_DIR = r'E:\\LEARN_5\\XuLyNgonNguTuNhien\\project\\models' # Thư mục gốc ban đầu\n",
    "\n",
    "print(f\"Sử dụng MODEL_SAVE_DIR: {MODEL_SAVE_DIR}\")\n",
    "if not os.path.exists(MODEL_SAVE_DIR):\n",
    "    print(f\"LỖI: Thư mục MODEL_SAVE_DIR '{MODEL_SAVE_DIR}' không tồn tại. Vui lòng kiểm tra lại đường dẫn.\")\n",
    "    exit()\n",
    "\n",
    "TOKENIZER_PATH = os.path.join(MODEL_SAVE_DIR, 'tokenizer.pkl')\n",
    "LABEL_ENCODER_PATH = os.path.join(MODEL_SAVE_DIR, 'label_encoder.pkl')\n",
    "MAX_LEN_PATH = os.path.join(MODEL_SAVE_DIR, 'max_len.pkl')\n",
    "BIGRU_MODEL_PATH = os.path.join(MODEL_SAVE_DIR, 'bigru_model.keras')\n",
    "BILSTM_MODEL_PATH = os.path.join(MODEL_SAVE_DIR, 'bilstm_model.keras')\n",
    "\n",
    "# Paths for TextCleaner\n",
    "STOPWORDS_FILE = 'E:\\\\LEARN_5\\\\XuLyNgonNguTuNhien\\\\project\\\\crawl\\\\stopwords.txt'\n",
    "ABBREVIATIONS_FILE = 'E:\\\\LEARN_5\\\\XuLyNgonNguTuNhien\\\\project\\\\crawl\\\\acronym.txt'\n",
    "VNCORENLP_MODEL_DIR = 'E:/LEARN_5/XuLyNgonNguTuNhien/vncorenlp'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cbaee93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Khởi tạo TextCleaner ---\n",
      "Đã tạo instance mới của TextCleaner.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Khởi tạo TextCleaner (Tương tự ví dụ của bạn) ---\n",
    "print(\"--- Khởi tạo TextCleaner ---\")\n",
    "cleaner_instance = None\n",
    "try:\n",
    "    if not os.path.exists(STOPWORDS_FILE): print(f\"CẢNH BÁO: File stopwords '{STOPWORDS_FILE}' không tồn tại.\")\n",
    "    if not os.path.exists(ABBREVIATIONS_FILE): print(f\"CẢNH BÁO: File viết tắt '{ABBREVIATIONS_FILE}' không tồn tại.\")\n",
    "    if not os.path.exists(VNCORENLP_MODEL_DIR): print(f\"CẢNH BÁO: Thư mục VnCoreNLP '{VNCORENLP_MODEL_DIR}' không tồn tại.\")\n",
    "\n",
    "    # Kiểm tra xem instance đã tồn tại chưa (mặc dù trong script độc lập này thì không cần thiết lắm)\n",
    "    if 'cleaner_instance' not in globals() or cleaner_instance is None:\n",
    "        cleaner_instance = TextCleaner(STOPWORDS_FILE, ABBREVIATIONS_FILE, VNCORENLP_MODEL_DIR)\n",
    "        print(\"Đã tạo instance mới của TextCleaner.\")\n",
    "    else:\n",
    "        print(\"Instance của TextCleaner đã tồn tại. Bỏ qua khởi tạo.\")\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi khi khởi tạo TextCleaner: {e}. Không thể làm sạch văn bản.\")\n",
    "    # Để script có thể tiếp tục (nếu muốn test phần tải model), không exit() ở đây\n",
    "    # nhưng hàm dự đoán sẽ không hoạt động nếu cleaner_instance là None.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "155bdb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tải các thành phần đã lưu ---\n",
      "Đã tải tokenizer từ E:\\LEARN_5\\XuLyNgonNguTuNhien\\project\\models\\tokenizer.pkl.\n",
      "Đã tải label encoder từ E:\\LEARN_5\\XuLyNgonNguTuNhien\\project\\models\\label_encoder.pkl.\n",
      "Đã tải max_len: 200 từ E:\\LEARN_5\\XuLyNgonNguTuNhien\\project\\models\\max_len.pkl\n",
      "Đã tải mô hình BiGRU từ E:\\LEARN_5\\XuLyNgonNguTuNhien\\project\\models\\bigru_model.keras.\n",
      "Đã tải mô hình BiLSTM từ E:\\LEARN_5\\XuLyNgonNguTuNhien\\project\\models\\bilstm_model.keras.\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Tải các thành phần đã lưu ---\n",
    "print(\"\\n--- Tải các thành phần đã lưu ---\")\n",
    "tokenizer = None\n",
    "label_encoder = None\n",
    "max_len = None\n",
    "bigru_model = None\n",
    "bilstm_model = None\n",
    "\n",
    "try:\n",
    "    with open(TOKENIZER_PATH, 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "    print(f\"Đã tải tokenizer từ {TOKENIZER_PATH}.\")\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi khi tải tokenizer: {e}.\")\n",
    "\n",
    "try:\n",
    "    with open(LABEL_ENCODER_PATH, 'rb') as handle:\n",
    "        label_encoder = pickle.load(handle)\n",
    "    print(f\"Đã tải label encoder từ {LABEL_ENCODER_PATH}.\")\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi khi tải label encoder: {e}.\")\n",
    "\n",
    "try:\n",
    "    with open(MAX_LEN_PATH, 'rb') as handle:\n",
    "        max_len = pickle.load(handle)\n",
    "    print(f\"Đã tải max_len: {max_len} từ {MAX_LEN_PATH}\")\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi khi tải max_len: {e}.\")\n",
    "\n",
    "try:\n",
    "    bigru_model = load_model(BIGRU_MODEL_PATH)\n",
    "    print(f\"Đã tải mô hình BiGRU từ {BIGRU_MODEL_PATH}.\")\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi khi tải mô hình BiGRU: {e}.\")\n",
    "\n",
    "try:\n",
    "    bilstm_model = load_model(BILSTM_MODEL_PATH)\n",
    "    print(f\"Đã tải mô hình BiLSTM từ {BILSTM_MODEL_PATH}.\")\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi khi tải mô hình BiLSTM: {e}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62e7c201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Chuẩn bị dữ liệu mẫu ---\n",
      "Dữ liệu mẫu đã được làm sạch.\n",
      "Văn bản đã làm sạch (200 ký tự đầu): \"pakistan công_bố thương_vong giao_tranh ấn_độ quân_đội pakistan công_bố báo_cáo thương_vong xung_đột ấn_độ tuần quân_nhân dân_thường thiệt_mạng cơ_quan truyền_thông liên_quân chủng quân_đội pakistan i...\"\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Dữ liệu mẫu và làm sạch (Tương tự ví dụ của bạn) ---\n",
    "print(\"\\n--- Chuẩn bị dữ liệu mẫu ---\")\n",
    "sample_title = \"Pakistan công bố thương vong trong giao tranh với Ấn Độ\"\n",
    "sample_description = \"Quân đội Pakistan công bố báo cáo thương vong đầu tiên trong cuộc xung đột với Ấn Độ tuần qua, cho hay 51 quân nhân và dân thường đã thiệt mạng.\"\n",
    "sample_content = \"Cơ quan Truyền thông Liên Quân chủng quân đội Pakistan (ISPR) ngày 13/5 công bố báo cáo về cuộc xung đột 19 ngày với Ấn Độ, kéo dài từ 22/4 đến 10/5, và đặt tên cho chiến dịch này là Marka-e-Haq (Trận chiến vì sự thật). ISPR thông báo 11 binh sĩ thuộc các đơn vị lục quân, không quân đã thiệt mạng trong các cuộc giao tranh, trong đó có chỉ huy phi đội Usman Yousuf. 78 quân nhân bị thương trong các đòn tập kích của lực lượng Ấn Độ. Pakistan cũng thống kê thương vong dân thường gồm 40 người thiệt mạng, trong đó có 7 phụ nữ và 15 trẻ em, cùng với 121 người bị thương, chủ yếu trong chiến dịch Sindoor của Ấn Độ vào rạng sáng 7/5. ISPR không thống kê bất cứ thiệt hại nào về khí tài trong báo cáo. Trước đó, quân đội Pakistan cho hay họ đã bắn hạ 5 tiêm kích và một máy bay không người lái của Ấn Độ. Quân đội Ấn Độ cũng thông báo đã vô hiệu hóa một số chiến đấu cơ Pakistan, nhưng không nêu chi tiết.\"\n",
    "\n",
    "cleaned_sample_text = \"\"\n",
    "if cleaner_instance:\n",
    "    try:\n",
    "        title_c, desc_c, content_c = cleaner_instance.process_text(sample_title, sample_description, sample_content)\n",
    "        cleaned_sample_text = title_c + \" \" + desc_c + \" \" + content_c\n",
    "        print(\"Dữ liệu mẫu đã được làm sạch.\")\n",
    "        print(f\"Văn bản đã làm sạch (200 ký tự đầu): \\\"{cleaned_sample_text[:200]}...\\\"\")\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi làm sạch dữ liệu mẫu: {e}\")\n",
    "else:\n",
    "    print(\"TextCleaner không khả dụng, không thể làm sạch dữ liệu mẫu.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d45cd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Hàm dự đoán (Tương tự ví dụ của bạn, nhưng cho RNN) ---\n",
    "def predict_new_text_rnn(cleaned_text_input, model_to_use, model_name_str,\n",
    "                         tokenizer_loaded, label_encoder_loaded, max_len_loaded):\n",
    "    # Kiểm tra các thành phần cần thiết\n",
    "    if model_to_use is None:\n",
    "        print(f\"Mô hình {model_name_str} chưa được tải hoặc có lỗi. Bỏ qua dự đoán.\")\n",
    "        return\n",
    "    if tokenizer_loaded is None:\n",
    "        print(\"Tokenizer chưa được tải. Bỏ qua dự đoán.\")\n",
    "        return\n",
    "    if label_encoder_loaded is None:\n",
    "        print(\"Label encoder chưa được tải. Bỏ qua dự đoán.\")\n",
    "        return\n",
    "    if max_len_loaded is None:\n",
    "        print(\"Max_len chưa được tải. Bỏ qua dự đoán.\")\n",
    "        return\n",
    "    if not cleaned_text_input or not cleaned_text_input.strip():\n",
    "        print(\"Văn bản đầu vào (đã làm sạch) rỗng. Không thể dự đoán.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n--- Dự đoán với {model_name_str} cho văn bản mới ---\")\n",
    "    print(f\"Văn bản đầu vào (200 ký tự đầu): \\\"{cleaned_text_input[:200]}...\\\"\")\n",
    "\n",
    "    # Tokenize and Pad\n",
    "    try:\n",
    "        sequence = tokenizer_loaded.texts_to_sequences([cleaned_text_input])\n",
    "        padded_sequence = pad_sequences(sequence, maxlen=max_len_loaded, padding='post', truncating='post')\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi trong quá trình tokenize hoặc padding: {e}\")\n",
    "        return\n",
    "\n",
    "    # Predict\n",
    "    try:\n",
    "        prediction_proba = model_to_use.predict(padded_sequence)\n",
    "        predicted_class_index = np.argmax(prediction_proba, axis=1)[0]\n",
    "        predicted_class_label = label_encoder_loaded.inverse_transform([predicted_class_index])[0]\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi trong quá trình dự đoán của mô hình: {e}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Chủ đề dự đoán: {predicted_class_label}\")\n",
    "    print(\"Xác suất dự đoán cho từng chủ đề:\")\n",
    "    if hasattr(label_encoder_loaded, 'classes_'):\n",
    "        for i, topic_class_name in enumerate(label_encoder_loaded.classes_):\n",
    "            print(f\"  - {topic_class_name}: {prediction_proba[0][i]:.4f}\")\n",
    "    else:\n",
    "        print(\"Không thể lấy tên các lớp từ label_encoder.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f929eb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Thực hiện dự đoán cho dữ liệu mẫu ---\n",
      "\n",
      "--- Dự đoán với BiGRU cho văn bản mới ---\n",
      "Văn bản đầu vào (200 ký tự đầu): \"pakistan công_bố thương_vong giao_tranh ấn_độ quân_đội pakistan công_bố báo_cáo thương_vong xung_đột ấn_độ tuần quân_nhân dân_thường thiệt_mạng cơ_quan truyền_thông liên_quân chủng quân_đội pakistan i...\"\n",
      "1/1 [==============================] - 13s 13s/step\n",
      "Chủ đề dự đoán: Quân sự\n",
      "Xác suất dự đoán cho từng chủ đề:\n",
      "  - AI: 0.0000\n",
      "  - Bóng đá: 0.0005\n",
      "  - Chuyển đổi số: 0.0000\n",
      "  - Chân dung: 0.0000\n",
      "  - Chính trị: 0.0067\n",
      "  - Chứng khoán: 0.0002\n",
      "  - Các môn thể thao khác: 0.0017\n",
      "  - Du học: 0.0051\n",
      "  - Dân sinh: 0.0000\n",
      "  - Ebank: 0.0006\n",
      "  - Giao thông: 0.0001\n",
      "  - Giáo dục 4.0: 0.0000\n",
      "  - Giải trí giới sao: 0.0000\n",
      "  - Giải trí làm đẹp: 0.0013\n",
      "  - Giải trí nhạc: 0.0018\n",
      "  - Giải trí phim: 0.0000\n",
      "  - Giải trí thời trang: 0.0000\n",
      "  - Hàng hóa: 0.0000\n",
      "  - Hậu trường thể thao: 0.0002\n",
      "  - Học tiếng anh: 0.0001\n",
      "  - Hồ sơ phá án: 0.0000\n",
      "  - Kinh doanh doanh nghiệp: 0.0000\n",
      "  - Kinh doanh quốc tế: 0.0005\n",
      "  - Người Việt 5 châu: 0.0000\n",
      "  - Nhịp sống: 0.0000\n",
      "  - Quân sự: 0.9770\n",
      "  - Quỹ Hy vọng: 0.0000\n",
      "  - Sân khấu mỹ thuật: 0.0000\n",
      "  - Sống khoẻ: 0.0000\n",
      "  - Thiết bị: 0.0000\n",
      "  - Thế giới tự nhiên: 0.0001\n",
      "  - Thị trường xe: 0.0037\n",
      "  - Tin tức Giáo dục: 0.0002\n",
      "  - Tin tức sức khoẻ: 0.0000\n",
      "  - Tổ ấm: 0.0000\n",
      "  - Việc làm: 0.0000\n",
      "  - Vũ trụ: 0.0001\n",
      "  - Ẩm thực: 0.0000\n",
      "\n",
      "--- Dự đoán với BiLSTM cho văn bản mới ---\n",
      "Văn bản đầu vào (200 ký tự đầu): \"pakistan công_bố thương_vong giao_tranh ấn_độ quân_đội pakistan công_bố báo_cáo thương_vong xung_đột ấn_độ tuần quân_nhân dân_thường thiệt_mạng cơ_quan truyền_thông liên_quân chủng quân_đội pakistan i...\"\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "Chủ đề dự đoán: Quân sự\n",
      "Xác suất dự đoán cho từng chủ đề:\n",
      "  - AI: 0.0001\n",
      "  - Bóng đá: 0.0000\n",
      "  - Chuyển đổi số: 0.0069\n",
      "  - Chân dung: 0.0000\n",
      "  - Chính trị: 0.0010\n",
      "  - Chứng khoán: 0.0000\n",
      "  - Các môn thể thao khác: 0.0006\n",
      "  - Du học: 0.0888\n",
      "  - Dân sinh: 0.0000\n",
      "  - Ebank: 0.0035\n",
      "  - Giao thông: 0.0006\n",
      "  - Giáo dục 4.0: 0.0044\n",
      "  - Giải trí giới sao: 0.0000\n",
      "  - Giải trí làm đẹp: 0.0013\n",
      "  - Giải trí nhạc: 0.0000\n",
      "  - Giải trí phim: 0.0000\n",
      "  - Giải trí thời trang: 0.0001\n",
      "  - Hàng hóa: 0.0003\n",
      "  - Hậu trường thể thao: 0.0004\n",
      "  - Học tiếng anh: 0.0001\n",
      "  - Hồ sơ phá án: 0.0000\n",
      "  - Kinh doanh doanh nghiệp: 0.0002\n",
      "  - Kinh doanh quốc tế: 0.0007\n",
      "  - Người Việt 5 châu: 0.0611\n",
      "  - Nhịp sống: 0.0111\n",
      "  - Quân sự: 0.8060\n",
      "  - Quỹ Hy vọng: 0.0001\n",
      "  - Sân khấu mỹ thuật: 0.0001\n",
      "  - Sống khoẻ: 0.0001\n",
      "  - Thiết bị: 0.0000\n",
      "  - Thế giới tự nhiên: 0.0000\n",
      "  - Thị trường xe: 0.0116\n",
      "  - Tin tức Giáo dục: 0.0003\n",
      "  - Tin tức sức khoẻ: 0.0000\n",
      "  - Tổ ấm: 0.0002\n",
      "  - Việc làm: 0.0001\n",
      "  - Vũ trụ: 0.0001\n",
      "  - Ẩm thực: 0.0001\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Thực hiện dự đoán (Tương tự ví dụ của bạn) ---\n",
    "print(\"\\n--- Thực hiện dự đoán cho dữ liệu mẫu ---\")\n",
    "if cleaned_sample_text: # Chỉ dự đoán nếu văn bản đã được làm sạch\n",
    "    if bigru_model:\n",
    "        predict_new_text_rnn(cleaned_sample_text, bigru_model, \"BiGRU\",\n",
    "                             tokenizer, label_encoder, max_len)\n",
    "    else:\n",
    "        print(\"Mô hình BiGRU không khả dụng để dự đoán.\")\n",
    "\n",
    "    if bilstm_model:\n",
    "        predict_new_text_rnn(cleaned_sample_text, bilstm_model, \"BiLSTM\",\n",
    "                             tokenizer, label_encoder, max_len)\n",
    "    else:\n",
    "        print(\"Mô hình BiLSTM không khả dụng để dự đoán.\")\n",
    "\n",
    "    if not bigru_model and not bilstm_model:\n",
    "        print(\"Không có mô hình RNN nào được tải thành công để thực hiện dự đoán.\")\n",
    "elif cleaner_instance is None:\n",
    "    print(\"Không thể dự đoán vì TextCleaner không được khởi tạo.\")\n",
    "else:\n",
    "    print(\"Không thể dự đoán vì dữ liệu mẫu chưa được làm sạch (có thể do lỗi ở TextCleaner).\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4efc6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Dự đoán cho dữ liệu mẫu thứ hai (tùy chọn) ---\n",
      "Dữ liệu mẫu 2 đã được làm sạch.\n",
      "\n",
      "--- Dự đoán với BiGRU cho văn bản mới ---\n",
      "Văn bản đầu vào (200 ký tự đầu): \"giá vàng giá vàng sjc vàng điều_chỉnh phiên đi ngang công_ty kinh_doanh vàng_bạc đá_quý đồng_loạt niêm_yết giá vàng sjc đồng giá vàng nhẫn ghi_nhận tương_tự biến_động ảnh_hưởng thị_trường vàng thế_giớ...\"\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "Chủ đề dự đoán: Hàng hóa\n",
      "Xác suất dự đoán cho từng chủ đề:\n",
      "  - AI: 0.0000\n",
      "  - Bóng đá: 0.0000\n",
      "  - Chuyển đổi số: 0.0001\n",
      "  - Chân dung: 0.0000\n",
      "  - Chính trị: 0.0000\n",
      "  - Chứng khoán: 0.0000\n",
      "  - Các môn thể thao khác: 0.0000\n",
      "  - Du học: 0.0000\n",
      "  - Dân sinh: 0.0000\n",
      "  - Ebank: 0.0002\n",
      "  - Giao thông: 0.0001\n",
      "  - Giáo dục 4.0: 0.0000\n",
      "  - Giải trí giới sao: 0.0000\n",
      "  - Giải trí làm đẹp: 0.0000\n",
      "  - Giải trí nhạc: 0.0000\n",
      "  - Giải trí phim: 0.0000\n",
      "  - Giải trí thời trang: 0.0000\n",
      "  - Hàng hóa: 0.9973\n",
      "  - Hậu trường thể thao: 0.0000\n",
      "  - Học tiếng anh: 0.0000\n",
      "  - Hồ sơ phá án: 0.0000\n",
      "  - Kinh doanh doanh nghiệp: 0.0003\n",
      "  - Kinh doanh quốc tế: 0.0006\n",
      "  - Người Việt 5 châu: 0.0001\n",
      "  - Nhịp sống: 0.0001\n",
      "  - Quân sự: 0.0000\n",
      "  - Quỹ Hy vọng: 0.0001\n",
      "  - Sân khấu mỹ thuật: 0.0000\n",
      "  - Sống khoẻ: 0.0000\n",
      "  - Thiết bị: 0.0000\n",
      "  - Thế giới tự nhiên: 0.0000\n",
      "  - Thị trường xe: 0.0000\n",
      "  - Tin tức Giáo dục: 0.0000\n",
      "  - Tin tức sức khoẻ: 0.0009\n",
      "  - Tổ ấm: 0.0000\n",
      "  - Việc làm: 0.0000\n",
      "  - Vũ trụ: 0.0000\n",
      "  - Ẩm thực: 0.0000\n",
      "\n",
      "--- Dự đoán với BiLSTM cho văn bản mới ---\n",
      "Văn bản đầu vào (200 ký tự đầu): \"giá vàng giá vàng sjc vàng điều_chỉnh phiên đi ngang công_ty kinh_doanh vàng_bạc đá_quý đồng_loạt niêm_yết giá vàng sjc đồng giá vàng nhẫn ghi_nhận tương_tự biến_động ảnh_hưởng thị_trường vàng thế_giớ...\"\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "Chủ đề dự đoán: Hàng hóa\n",
      "Xác suất dự đoán cho từng chủ đề:\n",
      "  - AI: 0.0000\n",
      "  - Bóng đá: 0.0000\n",
      "  - Chuyển đổi số: 0.0000\n",
      "  - Chân dung: 0.0000\n",
      "  - Chính trị: 0.0000\n",
      "  - Chứng khoán: 0.0006\n",
      "  - Các môn thể thao khác: 0.0004\n",
      "  - Du học: 0.0001\n",
      "  - Dân sinh: 0.0003\n",
      "  - Ebank: 0.0005\n",
      "  - Giao thông: 0.0001\n",
      "  - Giáo dục 4.0: 0.0000\n",
      "  - Giải trí giới sao: 0.0000\n",
      "  - Giải trí làm đẹp: 0.0000\n",
      "  - Giải trí nhạc: 0.0000\n",
      "  - Giải trí phim: 0.0000\n",
      "  - Giải trí thời trang: 0.0000\n",
      "  - Hàng hóa: 0.9736\n",
      "  - Hậu trường thể thao: 0.0000\n",
      "  - Học tiếng anh: 0.0000\n",
      "  - Hồ sơ phá án: 0.0000\n",
      "  - Kinh doanh doanh nghiệp: 0.0008\n",
      "  - Kinh doanh quốc tế: 0.0221\n",
      "  - Người Việt 5 châu: 0.0001\n",
      "  - Nhịp sống: 0.0002\n",
      "  - Quân sự: 0.0000\n",
      "  - Quỹ Hy vọng: 0.0000\n",
      "  - Sân khấu mỹ thuật: 0.0000\n",
      "  - Sống khoẻ: 0.0001\n",
      "  - Thiết bị: 0.0000\n",
      "  - Thế giới tự nhiên: 0.0000\n",
      "  - Thị trường xe: 0.0003\n",
      "  - Tin tức Giáo dục: 0.0000\n",
      "  - Tin tức sức khoẻ: 0.0002\n",
      "  - Tổ ấm: 0.0000\n",
      "  - Việc làm: 0.0000\n",
      "  - Vũ trụ: 0.0000\n",
      "  - Ẩm thực: 0.0004\n",
      "\n",
      "--- Kết thúc chương trình dự đoán ---\n"
     ]
    }
   ],
   "source": [
    "# Ví dụ với dữ liệu thứ hai (bạn có thể thêm)\n",
    "print(\"\\n--- Dự đoán cho dữ liệu mẫu thứ hai (tùy chọn) ---\")\n",
    "sample_title_2 = \"Giá vàng trong nước bất ngờ tăng mạnh\"\n",
    "sample_description_2 = \"Giá vàng SJC và các loại vàng khác đều điều chỉnh tăng sau nhiều phiên đi ngang.\"\n",
    "sample_content_2 = \"Sáng nay, các công ty kinh doanh vàng bạc đá quý lớn đồng loạt niêm yết giá vàng SJC tăng từ 200.000 đến 300.000 đồng mỗi lượng. Giá vàng nhẫn cũng ghi nhận mức tăng tương tự. Sự biến động này được cho là do ảnh hưởng từ thị trường vàng thế giới và tỷ giá USD/VND. Nhiều nhà đầu tư tỏ ra quan tâm và tìm kiếm cơ hội giao dịch.\"\n",
    "\n",
    "cleaned_sample_text_2 = \"\"\n",
    "if cleaner_instance:\n",
    "    try:\n",
    "        title_c2, desc_c2, content_c2 = cleaner_instance.process_text(sample_title_2, sample_description_2, sample_content_2)\n",
    "        cleaned_sample_text_2 = title_c2 + \" \" + desc_c2 + \" \" + content_c2\n",
    "        print(\"Dữ liệu mẫu 2 đã được làm sạch.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi làm sạch dữ liệu mẫu 2: {e}\")\n",
    "\n",
    "if cleaned_sample_text_2:\n",
    "    if bigru_model:\n",
    "        predict_new_text_rnn(cleaned_sample_text_2, bigru_model, \"BiGRU\",\n",
    "                             tokenizer, label_encoder, max_len)\n",
    "    if bilstm_model:\n",
    "        predict_new_text_rnn(cleaned_sample_text_2, bilstm_model, \"BiLSTM\",\n",
    "                             tokenizer, label_encoder, max_len)\n",
    "\n",
    "print(\"\\n--- Kết thúc chương trình dự đoán ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
